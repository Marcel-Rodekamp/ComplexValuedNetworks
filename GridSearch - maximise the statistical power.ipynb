{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration: Complex-Valued Affine Coupling Layer\n",
    "\n",
    "This notebook is meant to show how the affine coupling layer - with complex-valued trainable parameters - works.\n",
    "To show a typical show case, the next lines of code implement the 2-site Hubbard model. \n",
    "For more information about the methods referr to [our paper](https://arxiv.org/abs/2203.00390)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything is set up to work in torch to make interfacing with the neural network easier\n",
    "import torch\n",
    "\n",
    "# plotting is done using matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# matplotlib works better with numpy.\n",
    "import numpy as np\n",
    "\n",
    "# For fitting wie simply use\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Easier looping\n",
    "import itertools as it\n",
    "\n",
    "\n",
    "# The Layers are implemented using torch.nn.Module:\n",
    "# Implementation the Paired (Random) Coupling Layer (PRCL)\n",
    "from layer import PRCL\n",
    "# Implementation of the Affine Coupling\n",
    "from layer import AffineCoupling\n",
    "\n",
    "# The Layers are set up to calculate the log det on the fly. \n",
    "# This requires a special implementation of the sequential container\n",
    "from layer import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code is absolutely not optimized for GPU nor could the \n",
    "# 2 site problem fill a GPU thus it might be best to keep it \n",
    "# with device = 'cpu'.\n",
    "torchTensorArgs = {\n",
    "    \"device\": torch.device('cpu'),\n",
    "    \"dtype\" : torch.cdouble\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation parameters\n",
    "\n",
    "The following cell defines the parameter of the Hubbard model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Number of time slices\n",
    "Nt   = 4\n",
    "\n",
    "# Controle the continuum limit with\n",
    "beta = 1\n",
    "\n",
    "# On site interaction\n",
    "U    = 1\n",
    "\n",
    "# chemical potential\n",
    "mu   = 1\n",
    "\n",
    "# lattice spacing\n",
    "delta= beta/Nt\n",
    "\n",
    "# Put to 0 if not desired:\n",
    "# tangent plane \n",
    "tpOffset = -6.97420945e-02 # Nt=4,beta=U=mu=1\n",
    "# tpOffset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change anything in this cell! \n",
    "# It provides named variables to increase readability of the code\n",
    "\n",
    "# number of ions in the lattice\n",
    "Nx = 2\n",
    "\n",
    "# Make all variables unit less\n",
    "U  = delta * U\n",
    "mu = delta * mu\n",
    "\n",
    "# hopping matrix (particles)\n",
    "# exp( \\kappa + C^p )\n",
    "expKappa_p = torch.zeros((Nx, Nx),**torchTensorArgs)\n",
    "expKappa_p[0, 0] = np.cosh(delta) * np.exp(mu)\n",
    "expKappa_p[0, 1] = np.sinh(delta) * np.exp(mu)\n",
    "expKappa_p[1, 0] = np.sinh(delta) * np.exp(mu)\n",
    "expKappa_p[1, 1] = np.cosh(delta) * np.exp(mu)\n",
    "\n",
    "# hopping matrix (holes)\n",
    "# exp( \\kappa + C^h )\n",
    "expKappa_h = torch.zeros((Nx, Nx),**torchTensorArgs)\n",
    "expKappa_h[0, 0] =  np.cosh(delta) * np.exp(-mu)\n",
    "expKappa_h[0, 1] = -np.sinh(delta) * np.exp(-mu)\n",
    "expKappa_h[1, 0] = -np.sinh(delta) * np.exp(-mu)\n",
    "expKappa_h[1, 1] =  np.cosh(delta) * np.exp(-mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M(phi,species):\n",
    "    r\"\"\"\n",
    "        \\params:\n",
    "            - phi: torch.tensor(Nt,Nx), configuration\n",
    "            - species: +1 for particles, -1 for holes\n",
    "        \n",
    "        M(phi)_{t',x'; t,x} = \\delta_{t',t} \\delta_{x',x} - exp(s*(\\Kappa+\\mu))_{x',x} exp(i*s*\\Phi_{t,x}) \\delta_{t',t+1} \n",
    "    \"\"\"\n",
    "    Nt,Nx = phi.shape\n",
    "    \n",
    "    M = torch.zeros((Nt, Nx, Nt, Nx), **torchTensorArgs)\n",
    "    \n",
    "    # determine the expression of exp(s*Kappa) from the species \n",
    "    if species == 1:\n",
    "        expKappa = expKappa_p\n",
    "    elif species == -1:\n",
    "        expKappa = expKappa_h\n",
    "    else:\n",
    "        return ValueError(f\"Fermion Matrix got wrong species argument. Must be +/- 1 but is {species}.\")\n",
    "    \n",
    "    # precompute the exponential of the configuration\n",
    "    \n",
    "    expphi = torch.exp(species*1.j*phi)\n",
    "    \n",
    "    ts = torch.arange(0,Nt-1)\n",
    "    M[ts,:,ts,:] = torch.eye(Nx,**torchTensorArgs)\n",
    "    \n",
    "    M[ts+1, :, ts, :] = -expKappa[:, :] * expphi[ts,None, :]\n",
    "    # bulk time slices\n",
    "    #for t in range(Nt - 1):\n",
    "        # \\delta_{t',t} \\delta_{x',x}\n",
    "       \n",
    "    \n",
    "    # \\delta_{t',t} \\delta_{x',x}\n",
    "    M[Nt - 1, :, Nt - 1, :] = torch.eye(Nx,**torchTensorArgs)\n",
    "    \n",
    "    # bundary time slice \n",
    "    # term t' = Nt = 0,  t = Nt-1\n",
    "        # exp(s*(\\Kappa+\\mu))_{x',x} exp(i*s*\\Phi_{t,x}) \\delta_{t',t+1}\n",
    "    \n",
    "    M[0, :, Nt-1, :] = expKappa[:, :] * expphi[Nt-1,None, :]\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to define the action we will need the log det of the matrices\n",
    "def logdetM(phi,species):    \n",
    "    r\"\"\"\n",
    "        \\params:\n",
    "            - phi: torch.tensor(Nt,Nx), configuration\n",
    "            - species: +1 for particles, -1 for holes\n",
    "        \n",
    "        \\log \\det [M(phi)_{t',x'; t,x}] \n",
    "    \"\"\"\n",
    "    # For torch to handle M as a matrix we can simply reshape the 4 rank tensor to a 2 rank tensor (i.e. matrix)\n",
    "    return torch.log(torch.linalg.det(M(phi,species).reshape(Nt*Nx,Nt*Nx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the action of the system\n",
    "def action(phi):\n",
    "    r\"\"\"\n",
    "        \\params:\n",
    "            - phi: torch.tensor(Nt,Nx), configuration\n",
    "            - species: +1 for particles, -1 for holes\n",
    "        \n",
    "        S(\\phi) = \\frac{1}{2U} \\phi^T \\phi - \\log{\\det{ M^p \\cdot M^h }}   \n",
    "    \"\"\"\n",
    "    return (phi*phi).sum()/(2*U) - logdetM(phi,+1) - logdetM(phi,-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalized MD hamiltonian\n",
    "def hamiltonian(phi,pi):\n",
    "    r\"\"\"\n",
    "        \\params:\n",
    "            - phi: torch.tensor(Nt,Nx), configuration\n",
    "            - species: +1 for particles, -1 for holes\n",
    "        \n",
    "        H(\\phi) = \\frac{1}{2} \\pi^T \\pi + S(\\phi)   \n",
    "    \"\"\"\n",
    "\n",
    "    return 0.5*(pi*pi).sum() + action(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The force term from log det M^p\n",
    "def TrMinvM(phi,species):\n",
    "    r\"\"\"\n",
    "        \\params:\n",
    "            - phi: torch.tensor(Nt,Nx), configuration\n",
    "            - species: +1 for particles, -1 for holes\n",
    "        \n",
    "        \\frac{d \\log{\\det{ M(\\phi) }}}{ d\\phi } = \\Tr{ M^{-1}(\\phi) \\cdot \\frac{dM(\\phi)}{d\\phi} }\n",
    "        \n",
    "        where \n",
    "        \n",
    "        \\frac{dM(\\phi)_{t',x'; t,x}} }{d\\phi_{t,x}} = -i*s* exp(s*(\\Kappa+\\mu))_{x',x} exp(i*s*\\phi_{t,x}) \\delta_{t',t+1} \n",
    "    \"\"\"\n",
    "    # Tr = d logdetM(\\phi)/d\\phi_{t,x}\n",
    "    Tr = torch.zeros((Nt,Nx),**torchTensorArgs)\n",
    "    \n",
    "    # determine the expression of exp(s*Kappa) from the species \n",
    "    if species == 1:\n",
    "        expKappa = expKappa_p\n",
    "    elif species == -1:\n",
    "        expKappa = expKappa_h\n",
    "    else:\n",
    "        return ValueError(f\"Force got wrong species argument. Must be +/- 1 but is {species}.\")\n",
    "    \n",
    "    expphi = torch.exp(species*1j*phi)\n",
    "    \n",
    "    # again reshape M for torch to understand it as a matrix\n",
    "    Minv = torch.linalg.inv(\n",
    "        M(phi,species).reshape(Nt * Nx, Nt * Nx)\n",
    "    ).reshape(Nt, Nx, Nt, Nx)\n",
    "    \n",
    "    ts = torch.arange(0,Nt-1)\n",
    "    \n",
    "    #bulk time slices\n",
    "    #for t in range(Nt-1): \n",
    "        #for x in range(Nx):\n",
    "            # temp_{t,x} = sum_{t'} M^{-1}_{t,x; t',x'} exp(s*(\\Kappa+\\mu))_{x',x} \\delta_{t',t+1}\n",
    "            # This is the matrix multiplication with y=x'\n",
    "            # The sum over t' is resolved with the delta_{t',t+1}\n",
    "        \n",
    "    temp = torch.diagonal(torch.tensordot(Minv[ts,:,ts+1,:],expKappa[:,:],dims=1), dim1 = 1, dim2 = -1)\n",
    "        \n",
    "        #print(temp)    \n",
    "            # (TrMinvM)_{t,x} = -i * s * temp_{t,x} * exp(i*s*\\phi_{t,x})\n",
    "    Tr[ts, :] = -1.j * species * temp[:] * expphi[ts, :]\n",
    "    \n",
    "    # boundary time slice\n",
    "    # term t = Nt=0, t' = Nt=-1 \n",
    "    #for x in range(Nx):\n",
    "        # temp_{Nt-1,x} = M^{-1}_{0,x; t'=0,x'} exp(s*(\\Kappa+\\mu))_{x',x} \\delta_{t'=0,t+1}tmp_{t,x} \n",
    "        #               = M^{-1}_{t,x,t+1} @ exp(Kappa) \n",
    "    temp = torch.diag(torch.tensordot(Minv[Nt-1,:,0,:],expKappa[:,:],dims=1))\n",
    "    # (TrMinvM)_{Nt-1,x} = i * s * tmp_{t,x} * exp(i*s*phi_{t,x})\n",
    "    Tr[Nt - 1, :] = 1.j * species * temp * expphi[Nt-1, :]\n",
    "\n",
    "    return Tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrMinvM_ph(phi):\n",
    "    r\"\"\"\n",
    "        \\params:\n",
    "            - phi: torch.tensor(Nt,Nx), configuration\n",
    "        \n",
    "         Compute the fermionic part of the force (see TrMinvM) for both species\n",
    "    \"\"\"\n",
    "    return TrMinvM(phi,+1) + TrMinvM(phi,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force(phi):\n",
    "    r\"\"\"\n",
    "        \\params:\n",
    "            - phi: torch.tensor(Nt,Nx), configuration\n",
    "            \n",
    "        F(phi) = - dS(phi)/dphi = - d/dphi ( 1/2U phi^2 - log det M^p - log det M^h )\n",
    "                                = - [ 1/U phi - Tr( M^{p,-1} dM^p/dphi + M^{h,-1} dM^h/dphi ) ]\n",
    "    \"\"\"\n",
    "    \n",
    "    return -(phi/U - TrMinvM_ph(phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Force test succeeded without error\n"
     ]
    }
   ],
   "source": [
    "testForce = True\n",
    "if testForce:\n",
    "    succeed = True\n",
    "    epsilon = 1e-4\n",
    "    \n",
    "    phi = torch.randn((Nt,Nx),**torchTensorArgs).real + 1j*tpOffset\n",
    "    \n",
    "    forceValue = force(phi)\n",
    "    \n",
    "    S = action(phi)\n",
    "    \n",
    "    for t,x in it.product(range(Nt),range(Nx)):\n",
    "        phiPeps = phi.clone()\n",
    "        phiPeps[t,x]+=epsilon\n",
    "        \n",
    "        SPeps = action(phiPeps)\n",
    "        \n",
    "        dS = (SPeps - S)/epsilon\n",
    "        \n",
    "        # force = -dS/dPhi\n",
    "        Re_err = torch.abs(dS.real+forceValue[t,x].real).item()\n",
    "        Im_err = torch.abs(dS.imag+forceValue[t,x].imag).item()\n",
    "        err    = torch.abs(dS+forceValue[t,x]).item()\n",
    "        \n",
    "        if Re_err >= epsilon*10:\n",
    "            print(f\"Re Force error[{t=},{x=}] = {Re_err:.1e} > {epsilon:.0e}\")\n",
    "            succeed = False\n",
    "        if Im_err >= epsilon*10:\n",
    "            print(f\"Im Force error[{t=},{x=}] = {Im_err:.1e} > {epsilon:.0e}\")\n",
    "            succeed = False\n",
    "        if err >= epsilon*10:\n",
    "            print(f\"Abs Force error[{t=},{x=}]= {err:.1e} > {epsilon:.0e}\")\n",
    "            succeed = False\n",
    "            \n",
    "    if succeed:\n",
    "        print(f\"Force test succeeded without error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leapfrog(phi0,pi0,trajLength,Nmd,direction = 1):\n",
    "    r\"\"\"\n",
    "        \\params:\n",
    "            - phi0: torch.tensor(Nt,Nx), start configuration \n",
    "            - pi0 : torch.tensor(Nt,Nx), momentum field (complex dtype but with vanishing imaginary part)\n",
    "            - trajLength: float, trajectory length i.e. time to which the eom are integrated\n",
    "            - Nmd : int, number of molecular dynamics steps \n",
    "            - direction: int, direction (+/-) in which the algorithm should integrade\n",
    "            \n",
    "        This function integrades the Hamilton Equation of Motion (see hamiltonian and force) using the \n",
    "        leapfrog algorithm.\n",
    "        \n",
    "        This algorithm is reversible up to numerical precision and energy preserving up to order epsilon^2 where\n",
    "        epsilon = trajLength/Nmd\n",
    "    \"\"\"\n",
    "    # deepcopy the fields to not change the original torch tensors\n",
    "    phi = phi0.clone()\n",
    "    pi = pi0.clone()\n",
    "    \n",
    "    # compute the step size and specify the integration direction \n",
    "    stepSize = direction*trajLength/Nmd \n",
    "    \n",
    "    # first half step\n",
    "    # x_{1/2} = x_{0} + 0.5*\\Delta t * p_{0}\n",
    "    phi+= 0.5 * stepSize * pi\n",
    "    \n",
    "    # a bunch of full steps\n",
    "    # p_{t+1} = p_{t} + \\Delta t Re(dS/dphi)\n",
    "    # x_{t+3/2} = x_{t+1/2} + \\Delta t * p_{t+1}\n",
    "    for _ in range(Nmd-1):\n",
    "        pi += stepSize * force(phi).real\n",
    "        phi+= stepSize * pi\n",
    "    \n",
    "    # final half step\n",
    "    # p_{Nmd-1} = p_{Nmd-2} + \\Delta t Re(dS/dphi)\n",
    "    # x_{Nmd-1} = x_{Nmd-3/2} + 0.5 \\Delta t * p_{Nmd-1}\n",
    "    pi += stepSize * force(phi).real\n",
    "    phi+= 0.5 * stepSize * pi\n",
    "    \n",
    "    return phi,pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set True to execute test, set False to skip test\n",
    "testLeapfrog = False\n",
    "\n",
    "if testLeapfrog:\n",
    "    # define test parameter \n",
    "    trajLengthList = torch.tensor([1])\n",
    "    NmdList = torch.arange(0,101,10)[1:]\n",
    "    \n",
    "    print(f\"Testing with:\\n\"\n",
    "         +f\"\\t * Trajectory lengths: {list(trajLengthList.numpy())}\\n\"\n",
    "         +f\"\\t * N_MD: {list(NmdList.numpy())}\\n\",\n",
    "          end = \"\"\n",
    "    )\n",
    "    \n",
    "    # free theory:\n",
    "    #phi_s = torch.zeros((Nt,Nx),**torchTensorArgs) \n",
    "    # interacting theory:\n",
    "    phi_s = torch.randn((Nt,Nx),**torchTensorArgs).real + 1j*tpOffset\n",
    "    # pi_s is of complex dtype but need to be real. \n",
    "    # As torchTensorArgs specifies makes the tensor complex (at least it should ;) \n",
    "    # randn will sample a real and imaginary part \n",
    "    # this means we need to take the real part and add a zero imaginary part again\n",
    "    pi_s  = torch.randn((Nt,Nx),**torchTensorArgs).real + 0j\n",
    "    \n",
    "    H0 = hamiltonian(phi_s,pi_s)\n",
    "    \n",
    "    reversibility_error = torch.zeros( size=(len(trajLengthList),len(NmdList)) )\n",
    "    energyConservation_error = torch.zeros( size=(len(trajLengthList),len(NmdList)) )\n",
    "    \n",
    "    for (tlID,trajLength),(NmdID,Nmd) in it.product(enumerate(trajLengthList),enumerate(NmdList)):\n",
    "        # forward\n",
    "        phi_lf,pi_lf = leapfrog(\n",
    "            phi0 = phi_s,\n",
    "            pi0  = pi_s ,\n",
    "            trajLength = trajLength,\n",
    "            Nmd    = Nmd,\n",
    "            direction = 1\n",
    "        )\n",
    "        \n",
    "        # backward\n",
    "        phi_e,pi_e = leapfrog(\n",
    "            phi0 = phi_lf,\n",
    "            pi0  = pi_lf ,\n",
    "            trajLength = trajLength,\n",
    "            Nmd    = Nmd,\n",
    "            direction = -1\n",
    "        )\n",
    "        \n",
    "        reversibility_error[tlID,NmdID] = (phi_s-phi_e).sum().abs() + (pi_s-pi_e).sum().abs()\n",
    "        energyConservation_error[tlID,NmdID] = ((hamiltonian(phi_lf,pi_lf)-H0).real/H0.real).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testLeapfrog:\n",
    "    # plotting Reversibility Error: Expected is zero within some round of errors\n",
    "    for tlID,trajLength in enumerate(trajLengthList):\n",
    "        plt.plot(NmdList, reversibility_error[tlID,:],'x', label = f\"Trajectory Length: {trajLength}\")\n",
    "    plt.xlabel(r\"$N_{MD}$\")\n",
    "    plt.ylabel(r\"$||\\Phi_s-\\Phi_e||+||\\pi_s-\\pi_e||$\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testLeapfrog:    \n",
    "    # plotting Energy Conservation Error: Expected is square dependency with trajectoryLength/Nmd\n",
    "    print(f\"Best Fit Results: A x² + B\")\n",
    "    for tlID,trajLength in enumerate(trajLengthList):\n",
    "        plt.plot(trajLength/NmdList, energyConservation_error[tlID,:],'x:', label = f\"Trajectory Length L={trajLength}\")\n",
    "        popt,_ = curve_fit(\n",
    "            f = lambda x,A,B: A*x**2+B,\n",
    "            xdata = (trajLength/NmdList).numpy(),\n",
    "            ydata = energyConservation_error[tlID,:].numpy()\n",
    "        )\n",
    "        popt,pcov = curve_fit(\n",
    "            f = lambda x,A,B: A*x**2+B,\n",
    "            xdata = (trajLength/NmdList).numpy(),\n",
    "            ydata = energyConservation_error[tlID,:].numpy(),\n",
    "            p0 = popt\n",
    "        )\n",
    "        abscissa = np.linspace(0, trajLength/torch.min(NmdList).item(),1000 )\n",
    "        ordinate = popt[0] * abscissa**2 + popt[1]\n",
    "        plt.plot(abscissa,ordinate,label = rf\"Best Fit(L={trajLength}): $A x^2 + B$\")\n",
    "        print(f\"* L = {trajLength}: \\n\"\n",
    "            + f\"\\t A = {popt[0]: .2e} \\u00b1 {np.sqrt(pcov[0,0]):.2e}\\n\"\n",
    "            + f\"\\t B = {popt[1]: .2e} \\u00b1 {np.sqrt(pcov[1,1]):.2e}\"\n",
    "        )\n",
    "        \n",
    "    plt.xlabel(r\"$\\varepsilon = \\frac{L}{N_{MD}}$\")\n",
    "    plt.ylabel(r\"$\\left\\vert\\Re{\\frac{H_L - H_0}{H_0}}\\right\\vert$\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMC(phi0, trajLength, Nmd, Nconf, burnIn, thermalization):\n",
    "    r\"\"\"\n",
    "        \\params:\n",
    "            - phi0:           torch.Tensor(Nt,Nx), start element of the markov chain\n",
    "            - trajLength:     float, Molecular Dynamics integration length, see leapfrog\n",
    "            - Nmd:            int,  number of integration steps, see leapfrog\n",
    "            - Nconf:          int, number of configurations (after burn in and without thermalization)\n",
    "            - burnIn:         int, number of configurations to be discarded at the beginning of the algorithm (thermalization from phi0)\n",
    "            - thermalization: int, number of configurations to be discarded between two markov elements (reducing the autocorrelation)\n",
    "    \n",
    "        Implementation of a HMC algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    def hmc_step(phi_n):\n",
    "        r\"\"\"\n",
    "            A HMC step if transformation is None!\n",
    "        \"\"\"\n",
    "        \n",
    "        # sample a momentum field pi ~ N(0,1)\n",
    "        pi = torch.normal(\n",
    "            mean = torch.zeros((Nt,Nx),**torchTensorArgs).real, \n",
    "            std  = torch.ones((Nt,Nx),**torchTensorArgs).real\n",
    "        ) + 0.j\n",
    "        \n",
    "        # Compute initial hamiltonian value\n",
    "        H0 = hamiltonian(phi_n,pi)\n",
    "        \n",
    "        # Integrate Hamiltons EoM to generate a proposal\n",
    "        phi,pi = leapfrog(\n",
    "            phi0 = phi_n,\n",
    "            pi0  = pi ,\n",
    "            trajLength = trajLength,\n",
    "            Nmd    = Nmd,\n",
    "        )\n",
    "        \n",
    "        # Compute final hamiltonian value\n",
    "        H1 = hamiltonian(phi,pi)\n",
    "        \n",
    "        \n",
    "        # accept reject\n",
    "        if torch.rand(1).item() <= torch.exp( -(H1-H0).real ).item():\n",
    "            return phi, 1\n",
    "        else:\n",
    "            return phi_n, 0\n",
    "        \n",
    "        # Compute final hamiltonian value\n",
    "        H1 = hamiltonian(phi,pi)\n",
    "        \n",
    "        # accept reject\n",
    "        if torch.rand(1).item() <= torch.exp( -(H1-H0).real ).item():\n",
    "            return phi, 1\n",
    "        else:\n",
    "            return phi_n, 0\n",
    "    \n",
    "    # create a list of configurations with length Nconf\n",
    "    markovChain = torch.zeros( (Nconf,Nt,Nx), **torchTensorArgs )\n",
    "    \n",
    "    # create a list of action values\n",
    "    action_full = torch.zeros( (Nconf+burnIn), **torchTensorArgs )\n",
    "    action_markovChain = torch.zeros( (Nconf), **torchTensorArgs )\n",
    "    \n",
    "    # perform burnIn calculations\n",
    "    phi_n = phi0.clone()\n",
    "    for n in range(burnIn):\n",
    "        phi_n,_ = hmc_step(phi_n)\n",
    "        action_full[n] = action(phi_n)\n",
    "\n",
    "    # store starting point of HMC\n",
    "    markovChain[0,:,:] = phi_n\n",
    "    action_markovChain[0] = action(markovChain[0])\n",
    "    \n",
    "    acceptenceRate = 0\n",
    "            \n",
    "    # perform markov chain calculation\n",
    "    for n in range(Nconf-1):\n",
    "        markovChain[n+1],acceptence = hmc_step(markovChain[n])\n",
    "        action_full[n+burnIn] = action(markovChain[n+1])\n",
    "        action_markovChain[n+1] = action_full[n+burnIn]\n",
    "            \n",
    "        acceptenceRate += acceptence\n",
    "        \n",
    "        if n != Nconf-2:\n",
    "            # intermediate thermalization\n",
    "            phi_n = markovChain[n+1]\n",
    "            for _ in range(thermalization):\n",
    "                phi_n,_ = hmc_step(phi_n)\n",
    "        \n",
    "    \n",
    "    return {\n",
    "        \"configs\": markovChain,\n",
    "        \"S\": action_markovChain,\n",
    "        \"S full\": action_full,\n",
    "        \"acceptence rate\": acceptenceRate/Nconf\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "testHMC = False\n",
    "\n",
    "if testHMC:\n",
    "    trajectoryLength = 1.5\n",
    "    N_moleculardynamics = 3\n",
    "    Nconf = 2_000\n",
    "    burnIn = 1_000\n",
    "    thermalization = 0\n",
    "\n",
    "    # And here is how it works without a Neural Network:\n",
    "    res = HMC(\n",
    "        phi0 = torch.rand(Nt,Nx,**torchTensorArgs).real+1.j*tpOffset, \n",
    "        trajLength = trajectoryLength, \n",
    "        Nmd = N_moleculardynamics, \n",
    "        Nconf = Nconf, \n",
    "        burnIn = burnIn, \n",
    "        thermalization = thermalization\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testHMC = False\n",
    "\n",
    "if testHMC:\n",
    "    # plot the action evolution\n",
    "    plt.plot(np.arange(0,burnIn+Nconf), res['S full'].real.numpy(), 'x', label = r\"$S[\\phi_n]$\")\n",
    "    S_est = np.ones(burnIn+Nconf)*res['S'].real.mean().item()\n",
    "    S_err = np.ones(burnIn+Nconf)*res['S'].real.std().item()\n",
    "    plt.plot( np.arange(0,burnIn+Nconf), S_est, 'r-', label = r\"$\\left\\langleS[\\phi_n]\\right\\rangle$\" )\n",
    "    plt.fill_between(np.arange(0,burnIn+Nconf),\n",
    "        S_est-S_err,\n",
    "        S_est+S_err,\n",
    "        color = 'r',\n",
    "        alpha = 0.4\n",
    "    )\n",
    "    plt.axvline(burnIn, color='k',linestyle ='-.', label = \"Burn In\")\n",
    "\n",
    "    plt.xlabel(r\"Markov Chain ID: $n$\")\n",
    "    plt.ylabel(r\"Action Value: $S[\\phi_n]$\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Action Evolution with burnIn={burnIn}\")\n",
    "\n",
    "    print(f\"Acceptence Rate = {res['acceptence rate']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLHMC(phiR0, trajLength, Nmd, Nconf, burnIn, transformation, thermalization):\n",
    "    r\"\"\"\n",
    "        \\params:\n",
    "            - phi0:           torch.Tensor(Nt,Nx), start element of the markov chain\n",
    "            - trajLength:     float, Molecular Dynamics integration length, see leapfrog\n",
    "            - Nmd:            int,  number of integration steps, see leapfrog\n",
    "            - Nconf:          int, number of configurations (after burn in and without thermalization)\n",
    "            - burnIn:         int, number of configurations to be discarded at the beginning of the algorithm (thermalization from phi0)\n",
    "            - transformation: torch.nn.Module, network trained to move the configuration to a sign problem reduced manifold\n",
    "            - thermalization: int, number of configurations to be discarded between two markov elements (reducing the autocorrelation)\n",
    "    \n",
    "        Implementation of a HMC algorithm, augmented with machine learning to alleviate the sign problem.\n",
    "    \"\"\"\n",
    "    \n",
    "    def hmc_step(phiM_n, phiR_n, logDetJ_NN_n):\n",
    "        \n",
    "        # sample a momentum field pi ~ N(0,1)\n",
    "        pi = torch.normal(\n",
    "            mean = torch.zeros((Nt,Nx),**torchTensorArgs).real, \n",
    "            std  = torch.ones((Nt,Nx),**torchTensorArgs).real\n",
    "        ) + 0.j\n",
    "        \n",
    "        # Compute initial hamiltonian value\n",
    "        S0 = action(phiM_n)\n",
    "        H0 = S0 + 0.5*(pi*pi).sum() - logDetJ_NN_n\n",
    "        \n",
    "        # Integrate Hamiltons EoM to generate a proposal\n",
    "        # This integration needs to be done on the real plane!\n",
    "        phiR,pi = leapfrog(\n",
    "            phi0 = phiR_n,\n",
    "            pi0  = pi,\n",
    "            trajLength = trajLength,\n",
    "            Nmd    = Nmd,\n",
    "        )\n",
    "        \n",
    "        # transform to the more optimal manifold\n",
    "        phiM, logDetJ_NN = transformation(phiR)\n",
    "        \n",
    "        # Compute final hamiltonian value\n",
    "        S1 = action(phiM)\n",
    "        H1 = S1 + 0.5*(pi*pi).sum() - logDetJ_NN\n",
    "        \n",
    "        # WHY DOES THE MOMENTUM FIELD REMAIN UNCHANGED?\n",
    "        \n",
    "        #print(\"the probability to accept is \", torch.exp( -(H1-H0).real ))\n",
    "\n",
    "        \n",
    "        # accept reject\n",
    "        if torch.rand(1).item() <= torch.exp( -(H1-H0).real ).item():\n",
    "            return phiM,phiR,logDetJ_NN, S1, 1\n",
    "        else:\n",
    "            return phiM_n,phiR_n,logDetJ_NN_n, S0, 0\n",
    "    \n",
    "    # create a list of configurations with length Nconf\n",
    "    # manifold configs\n",
    "    markovChainM = torch.zeros( (Nconf,Nt,Nx), **torchTensorArgs )\n",
    "    # real plane configs\n",
    "    markovChainR = torch.zeros( (Nconf,Nt,Nx), **torchTensorArgs )\n",
    "    \n",
    "    # create a list of action values\n",
    "    action_full = torch.zeros( (Nconf+burnIn), **torchTensorArgs )\n",
    "    action_markovChain = torch.zeros( (Nconf), **torchTensorArgs )\n",
    "    \n",
    "    # create a list of weights i.e. logDet J_NN\n",
    "    logDetJ_NN_full = torch.zeros( (Nconf+burnIn), **torchTensorArgs )\n",
    "    logDetJ_NN_markovChain = torch.zeros( (Nconf), **torchTensorArgs )\n",
    "    \n",
    "    # perform burnIn calculations\n",
    "    phiR_n = phiR0.clone()\n",
    "    phiM_n, logDetJ_NN_n = transformation(phiR_n)\n",
    "    for n in range(burnIn):\n",
    "        phiM_n,phiR_n,logDetJ_NN_n,S_n,_ = hmc_step(phiM_n,phiR_n,logDetJ_NN_n)\n",
    "        action_full[n] = S_n\n",
    "        #print(logDetJ_NN_n)\n",
    "        logDetJ_NN_full[n] = logDetJ_NN_n\n",
    "\n",
    "    # store starting point of HMC\n",
    "    markovChainM[0,:,:] = phiM_n\n",
    "    markovChainR[0,:,:] = phiR_n\n",
    "    action_markovChain[0] = action_full[burnIn-1]\n",
    "    logDetJ_NN_markovChain[0] = logDetJ_NN_full[burnIn-1]\n",
    "    \n",
    "    acceptenceRate = 0\n",
    "    \n",
    "    logDetJ_NN_n = logDetJ_NN_markovChain[0] \n",
    "            \n",
    "    # perform markov chain calculation\n",
    "    for n in range(Nconf-1):\n",
    "        markovChainM[n+1],markovChainR[n+1],logDetJ_NN_markovChain[n+1],action_markovChain[n],acceptence = \\\n",
    "            hmc_step(phiM_n,phiR_n,logDetJ_NN_n)\n",
    "        \n",
    "        action_full[n+burnIn] = action_markovChain[n]\n",
    "        logDetJ_NN_full[n+burnIn] = logDetJ_NN_markovChain[n+1]\n",
    "        \n",
    "            \n",
    "        acceptenceRate += acceptence\n",
    "        \n",
    "        phiM_n = markovChainM[n+1]\n",
    "        phiR_n = markovChainR[n+1]\n",
    "        logDetJ_NN_n = logDetJ_NN_markovChain[n+1]\n",
    "        if n != Nconf-2:\n",
    "            for _ in range(thermalization):\n",
    "                phiM_n,phiR_n,logDetJ_NN_n,S_n,_ = hmc_step(phiM_n,phiR_n,logDetJ_NN_n)\n",
    "        \n",
    "    return {\n",
    "        \"configsM\": markovChainM,\n",
    "        \"configsR\": markovChainR,\n",
    "        \"S\": action_markovChain,\n",
    "        \"S full\": action_full,\n",
    "        \"log Det J_NN\": logDetJ_NN_markovChain,\n",
    "        \"log Det J_NN full\": logDetJ_NN_full,\n",
    "        \"acceptence rate\": acceptenceRate/Nconf\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTransformation(torch.nn.Module):\n",
    "    def __init__(self, Nt, Nx):\n",
    "        super(LinearTransformation, self).__init__()\n",
    "        self.register_parameter(name='bias', param=torch.nn.Parameter(torch.zeros((Nt, Nx//2), **torchTensorArgs)))\n",
    "        self.register_parameter(name='weight', param=torch.nn.Parameter(torch.zeros((Nt, Nx//2, Nt, Nx//2), **torchTensorArgs)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        return torch.tensordot(x,self.weight,dims=([-1,-2],[0,1])) + self.bias\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a random PRACL layer to test the transformation\n",
    "def generate_parameters(internalLayer):\n",
    "    \n",
    "    layer = []\n",
    "    for _ in range(internalLayer-1):\n",
    "        \n",
    "        \n",
    "        d = LinearTransformation(Nt, Nx)\n",
    "        \n",
    "        layer.append(d)\n",
    "        layer.append(torch.nn.Softsign())\n",
    "        \n",
    "    e = LinearTransformation(Nt, Nx)\n",
    "   \n",
    "    layer.append(e)\n",
    "    \n",
    "    return torch.nn.Sequential(*layer)\n",
    "\n",
    "def generate_coupling(internalLayer):    \n",
    "    return AffineCoupling( m = generate_parameters(internalLayer), a = generate_parameters(internalLayer) )\n",
    "\n",
    "numPRACLLayers = 1\n",
    "internalLayer = 2\n",
    "NN = [] \n",
    "\n",
    "for _ in range(numPRACLLayers):\n",
    "    NN.append(\n",
    "        PRCL(\n",
    "            Nt,\n",
    "            Nx,\n",
    "            coupling1 = generate_coupling(internalLayer),\n",
    "            coupling2 = generate_coupling(internalLayer),\n",
    "        )\n",
    "    )\n",
    "\n",
    "NN = Sequential(NN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Loss(phi, logDet):\n",
    "    n,Nt,Nx = phi.shape\n",
    "    S = torch.zeros(n,**torchTensorArgs)\n",
    "    for i in range(n):\n",
    "        S[i] = action(phi[i,:,:])\n",
    "    S -= logDet\n",
    "    return torch.exp(-S).abs().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fb29bcf9e14d5aa384342b23890aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py:173: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 17.4 s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAF6CAYAAABC7bKLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1d3H8c/PENk3QdllhwABgqJIsWDBfUWKKCIVsFq3qvUpfXi6aW3tora1ti5tVaitlrrVpdpNK1WqT+vyuLALyCbIvm8S+D1/nJvMJEySSSaTySTf9+s1r8zce+69v7mZzC/nnnPPMXdHREREqu6ITAcgIiKS7ZRMRUREUqRkKiIikiIlUxERkRQpmYqIiKRIyVRERCRFSqaScWY2y8y+l6Fjm5nNNLOtZvafNB3jWDPbZWY51Vm2tjCza8xsfRR3m+hnj0zHBdl5PiU7KZnKYcxsRfTl2DRu2RfNbE4Gw0qXk4HTgM7ufmLplWY2xczmpnIAd1/l7s3c/WB1lq0NzCwX+AlwehT35ujn8gzFs8LMTi16XRvPp5lNMLPXzWxPor8pMysws7ej9W+bWUGp9V8xs0/MbLuZPWxmDePWHWVmfzSz3Wa20swurYG3JCiZStkaADdmOojKqkINpCuwwt131+Ax65J2QCNgfroPZGYN0n2MGrIFuBv4YekVZnYk8CzwO6A18Bvg2Wg5ZnYGMAMYA3QDegDfidvFvcCnhN/LJOB+MxuQrjcicdxdDz1KPIAVhD/YLUCraNkXgTnR826AAw3itpkDfDF6PgX4F/BTYBuwHPhMtHw1sAG4PG7bWcADwN+BncA/ga5x6/OidVuAxcCEUtveD7wI7AZOTfB+OgLPRdsvBa6Mll8B7AMOAruA75Tarl+p9dvKOiZwDvB/wI7oPd4at58S5ys6V9+NztFO4G9A28qWjdZ/AVgJbAa+Ff3uDjsHUdnGwI+j8tuBuUDjaN35hIS4LTpmv1Kfh68C70fb/YGQQPtE79+j8/OPqLwDvaLnbYDno/PyJvA9YG4VPkdbom17Av+I3u8m4FFin9HfAoeAvVE8X0twPhN+FqJ1twKPA49E53o+MDRu/X8DH0frFgNjUvw7K/6bilt2enQMi1u2Cjgzev4Y8P24dWOAT6LnTQmJtE/c+t8CP8z0d0p9eKhmKmV5i/DF9tUqbj+M8OXbhvAFMBs4AegFXAb8wsyaxZWfREgabYF3CV+SRJea/x7t4xhgInBfqf+2LwVuB5oTEkRpvwfWEL5IxwPfN7Mx7v4QcDXwhodLgbfEb+TuC0utb1XOMXcTElsrQmK9xszGlnN+LgWmRu/pSMo/zwnLmll/4D7CuesAtAQ6lbOfu4DjCf/YHEVINofMrA/hHN0EHE34J+H5otpQZAJwJtAdGARMcfclQNHvoZW7j05wzHsJ56Y9cHn0qIxhhH/GjiGcbwN+QPhd9gO6EJIg7j6ZkHjOi35fdyTYX8LPQtz68wmf1VaEpPsLADPrC1wPnODuzYEzCP9kYGYnm9m2Sr6vsgwA3vcoE0beJ3aeBwDvxa17D2hnZm0I/9wcjH4v8etVM60BSqZSnm8DXzazo6uw7UfuPtNDW9UfCF96t7n7fnf/G+E/6F5x5V9w91fdfT/wDWC4mXUBziVchp3p7oXu/g7wFOGLsMiz7v4vdz/k7vvig4j2cTLw3+6+z93fBR4EJlfhPcUrcUx3n+PuH0Sv3yd8aY8qZ/uZ7r7E3fcSakMFVSg7Hnje3ee6+6eE31fCwbbN7AhgGnCju3/s7gfd/fXofF9MOP9/d/cDhKTbmJB0i9zj7mvdfQuhpllevEXHzAE+D9zi7nvcfQHhsmVlrHX3n0e/+73uvjSKc7+7byS015Z3nuPjSeazMNfdX4w+t78FBkfLDwINgf5mluvuK9x9GUB0/uP/0UpFM0LtP952wj9tidYXPW+exLaSRkqmUiZ3nwf8iXDJt7LWxz3fG+2v9LL4munquOPuIlyG60ho0xxmZtuKHoSaWPtE2ybQEdji7jvjlq2k/BpcMkoc08yGmdkrZrbRzLYTarRty9n+k7jneyh5LpIt25GS520P4fJnIm0Jl2aXJVjXkXBOivZzKNpv/DmqTLxFjia0vcefq/J+V4mUPs/HmNlsM/vYzHYQ2hbLO8/xkvkslH6fjcysgbsvJdTcbwU2RDF0rOR7ScYuoEWpZS0Il5YTrS96vjOJbSWNlEylIrcAV1LyC6eos06TuGXxya0quhQ9iS7/HgWsJXyZ/tPdW8U9mrn7NXHbljf10VrgKDOL/+/8WEK7VDLK2nfp5Y8RLgt2cfeWhDZgS/IYVbUO6Fz0wswaEy6rJ7KJ0P7bM8G6tYR/Wor2Y4TfR7LnqCwbgcL4GIn7PZPc56j0ef5BtGyQu7cgNBlYOeXjpfRZcPfH3P1kwrly4EfJbFdJ84FB0e+gyCBiHbzmE6stEz1f7+6bgSVAAzPrXWp92juHiZKpVCD6j/wPwA1xyzYSvoAuM7McM5tG4i/pyjg7ans6ktB2+m93X02oGfcxs8lmlhs9TjCzfknGvxp4HfiBmTUys0GEjkePJhnXeqBzqfbDRJoTaj37zOxEQjtnuj0JnGdmn4ni+w5lJPCotvkw8BMz6xj93oZHt1U8DpxjZmOiW13+C9hPOG9VFl0qfRq41cyamFkeoV25aH1VPkfNiTqDmVknYHqp9esJPVwTxVPlz4KZ9TWz0dH52ke4slKl222i99qIUGs/IoolN1o9J9rvDWbW0Myuj5b/I/r5CHCFmfU3s9bANwkd4vDQI/1p4DYza2pmI4ALCJerJc2UTCUZtxF6Csa7kvBFtpnQwSGlL15Cze4WwuXd4wmXcokuyZ0OXEKoWXxCqBE0TLybhCYSenWuBf5IaMP7e5Lb/oPwn/0nZrapnHLXEr7EdhLaLh+vRHxV4u7zgS8TOsysI1zO20BIhIl8FfiA0Kt2C+E8HuHuiwk1vJ8TarDnETrxfFoNYV5P6Bj1CeFL/fel4qvs5+g7wHGEtsAXCMkj3g+Ab0ZNAok6dVX1s9CQcCvLpui9HAN8HcDMPmtmu5LYR5HJhGR8P/DZ6PmvAaJzPpbwT8c2Qjv32KLfhbv/BbgDeIVwiXol4e+myLWE9u4NhHN9TfQ5kTSzkp3GRCRbRZfHtwG93f2jTMeTiJn9CGjv7pXt1StSq6lmKpLFzOy86BJqU0Iv3A+IbtmoDcwsz8wGWXAi4bLqHzMdl0h1UzIVyW4XEC5ZrgV6A5d47brc1JxwKXY34dL3jwkj/IjUKbrMKyIikiLVTEVERFKkZCqSRczs62b2YPS8m5l5HRoAXiRrKZmKpEmU6HZbmE+z6PG1VPbp7t939y9WV4xlMbPrzewtM9tvZrOSKF/mtGBVOHaZU5BF917+1MzWWpiD9r64ezRFMkbJVCS9BkcjNhU9Eg2+XhutJczS8nBFBa3iacGSZhVMQRYdZyiQTxjY/TjCwAUiGaVkKpIBZnarmT1pZn8ws51m9o6ZDY5b/9/R+LM7zWyxRTObRNv9rox9djSz58xsi5ktNbMrSx3vcTN7JNrnfDMbWlZ87v60uz9D2WP9xrsceMjd57v7VsIIVlNKxfWUhXGLPzKzG8raEXAKYWSgu6PB7O8hjOpUNCPNeYRB97dEIyjdQxjYQCSjlExFMucC4AnCOMSPAc9EwyWWOd1XBao0vRhAdLn0viq+jzKnBbMwW83z0bJOhNrrTVFttqx9lTcFmVFyyEQjDPfYsoqxi1QLJVOR9HrH4ma8KZVE3nb3J6Npz35CmNXlJMqZ7qssltr0Yrj7te5+bRXfY3nTgp0AHO3ut7n7p+6+nDB03iVJ7qtof0WD0/8ZuNHMjjaz9sTGjG6CSAapF6BIeh0XTRaQSPz0aYfMbA3Q0d1fM7Oi6b4GmNlfgZvdfW05xylrerH4S7llTS9WWIn3k0h504KdCHS0kpNn5wCvAZQa07Z/gn0V7a/ofd1OqFm/Sxjj99fAEMJYtCIZo5qpSObETzt3BGGqsrVQpem+Up1qLhXlTQu2mjBRfPwUes3d/WyAUp2zVlHBFGTRBOHXu3snd+9BaNN9O6pti2SMkqlI5hxvZuOi+0RvItS0/rcq031Vw1RzJZhZg2iasBwgJ9pnWVeyypwWDPgPsCPqUNXYwvRj+WZ2Qhn7mkM5U5CZWaeoQ5OZ2UnAtyg5a4pIRiiZiqTXe6XuM707bt2zwMXAVkLb5rio/bTM6b4qUOWp5szsATN7IG7RNwlJfAZhera90TLM7NjovRwL5U8LFtUYzwMKgI+i9/QgYVq2w1Q0BRlhvtPXCWP9/gaY4e5/S+Y9iqSTxuYVyQAzuxXo5e6XZToWEUmdaqYiIiIpUjIVERFJkS7zioiIpEg1UxERkRQpmYqIiKRIyVRERCRFSqYiIiIpUjIVERFJkZKpiIhIipRMRUREUqRkKiIikiIlUxERkRQpmYqIiKRIyVRERCRFSqYiIiIpUjIVERFJkZKpiIhIipRMRUREUqRkKiIikiIlU5EsYGafNbPFmY5DRBJTMhWpgJmtMLNTMxmDu7/m7n0zGUMRMzvFzNZU8z7HmNkiM9tjZq+YWddyyh5lZn80s91mttLMLk12Xxb8yMw2R487zMzi1heY2Wtmtt3M1pjZt6vzfUrdpWQqUguYWU6mY4DiZFOj3wtm1hZ4GvgWcBTwFvCHcja5F/gUaAdMAu43swFJ7usqYCwwGBgEnAt8KW79Y8Cr0bajgGvM7PzU3qHUB0qmIlVkZkeY2QwzWxbVch43s6Pi1j9hZp9EtZxXi77wo3WzzOx+M3vRzHYDn4tqwF81s/ejbf5gZo2i8iVqg+WVjdZ/zczWmdlaM/uimbmZ9Srjfcwxs9vN7F/AHqCHmU01s4VmttPMlpvZl6KyTYE/Ax3NbFf06FjRuajAOGC+uz/h7vuAW4HBZpaXINamwOeBb7n7LnefCzwHTE5yX5cDP3b3Ne7+MfBjYErcIboBj7r7QXdfBswFBiBSASVTkaq7gVDLGQV0BLYSak1F/gz0Bo4B3gEeLbX9pcDtQHPClzbABOBMoDuh5jSlnOMnLGtmZwI3A6cCvaL4KjKZUGtrDqwENhBqbS2AqcBPzew4d98NnAWsdfdm0WNtReciSvolLsfGGQC8V/QiOsYyEiexPsBBd18St+y9uLIV7avE+lLbAtwNfMHMcs2sLzAceKmMuEWKKZmKVN2XgG9EtZz9hFrQeDNrAODuD7v7zrh1g82sZdz2z7r7v9z9UFSLArjH3de6+xbgeaCgnOOXVXYCMNPd57v7HuA7SbyXWVH5Qnc/4O4vuPsyD/4J/A34bArnYpC7P1bGts2A7aWWbSck9sqWrez67UCzuHbTPwHjgb3AIuAhd3+zjLhFiimZilRdV+CPZrbNzLYBC4GDQDszyzGzH0aXPXcAK6Jt2sZtvzrBPj+Je76H8OVflrLKdiy170THKa1EGTM7y8z+18y2RO/tbErGXlqZ5yKJY+8i1IDjtQB2VqFsZde3AHa5u0eXpf8C3AY0AroAZ5jZtUm8B6nnlExFqm41cJa7t4p7NIra4i4FLiBcam1JaIsDsLjtPU1xrQM6x73uksQ2xbGYWUPgKeAuoJ27twJeJBZ7orjLOxcVmU/oEFR0/KZAz2h5aUuABmbWO27Z4LiyFe2rxPpS2/YgXEJ+JKqhrwFmE/6RECmXkqlIcnLNrFHcowHwAHB70a0XZna0mV0QlW8O7Ac2A02A79dgrI8DU82sn5k1ASp7e8eRQENgI1BoZmcBp8etXw+0KXXJurxzUZE/Avlm9vmoE9W3gffdfVHpglEb6NPAbWbW1MxGEP5p+W2S+3oEuNnMOplZR+C/gFnRuiUhdLs06lDVHriYkm2sIgkpmYok50VCO1rR41bgZ4SepH8zs53A/wLDovKPEDryfAwsiNbVCHf/M3AP8AqwFHgjWrU/ye13EjoUPU7oSHQp4X0WrV8E/B5YHl3W7Uj55wIzm29mk8o43kZCD93bo+MNAy6J2/brZvbnuE2uBRoTOkn9HrjG3ecnsy/gl4T25Q+AecAL0TLcfQehN/BXom3fjcrcnsRpk3rO3NN1pUlEagMz60dICg3dvTDT8YjURaqZitRBZnahmR1pZq2BHwHPK5GKpI+SqUjd9CVCm+cyQq/aazIbjkjdpsu8IiIiKVLNVEREJEVKpiIiIilqkOkAaqu2bdt6t27dMh2GiIjUEm+//fYmdz860Tol0zJ069aNt956K9NhiIhILWFmK8tap8u8IiIiKVIyFRERSZGSqYiISIrUZloJBw4cYM2aNezbt6/iwiKV0KhRIzp37kxubm6mQxGRKlAyrYQ1a9bQvHlzunXrRmwuYZHUuDubN29mzZo1dO/ePdPhiEgV6DJvJezbt482bdookUq1MjPatGmjKx4iWUzJtJKUSCUd9LkSyW5Kpllk8+bNFBQUUFBQQPv27enUqVPx608//bTC7efMmcPrr7+ecN2sWbO4/vrrqztkAJ544gn69evH5z73uWrb57Zt27jvvvuKX69du5bx48dX2/5FRCpDyTSLtGnThnfffZd3332Xq6++mq985SvFr4888sgKty8vmabTQw89xH333ccrr7xSbfssnUw7duzIk08+WW37FxGpDCXTLPf2228zatQojj/+eM444wzWrVsHwD333EP//v0ZNGgQl1xyCStWrOCBBx7gpz/9KQUFBbz22mtl7nPlypWMGTOGQYMGMWbMGFatWgWEGmZ+fj6DBw9m5MiRAMyfP58TTzyRgoICBg0axIcfflhiX7fddhtz587l6quvZvr06YfVgM8991zmzJkDQLNmzfjGN77B4MGDOemkk1i/fj0A69ev58ILL2Tw4MEMHjyY119/nRkzZrBs2TIKCgqYPn06K1asID8/Hwht21OnTmXgwIEMGTKkOInPmjWLcePGceaZZ9K7d2++9rWvVcNvQERqI3fYsAFefRV+9StYWebYRdV2QNcjweP444/30hYsWHDYsky55ZZb/I477vDhw4f7hg0b3N199uzZPnXqVHd379Chg+/bt8/d3bdu3Vq8zZ133plwfzNnzvTrrrvO3d3PPfdcnzVrlru7P/TQQ37BBRe4u3t+fr6vWbOmxD6vv/56/93vfufu7vv37/c9e/Yctu9Ro0b5m2++edhx3N3POeccf+WVV9zdHfDnnnvO3d2nT5/u3/3ud93dfcKECf7Tn/7U3d0LCwt927Zt/tFHH/mAAQOK9xP/+q677vIpU6a4u/vChQu9S5cuvnfvXp85c6Z3797dt23b5nv37vVjjz3WV61aVf6JrkG16fMlki0OHHBfvNj92Wfdf/Qj96lT3YcPd2/d2j2k1PD47W9TPxbwlpeRM3RrTFXddBO8+2717rOgAO6+O+ni+/fvZ968eZx22mkAHDx4kA4dOgAwaNAgJk2axNixYxk7dmylwnjjjTd4+umnAZg8eXJxDW7EiBFMmTKFCRMmMG7cOACGDx/O7bffzpo1axg3bhy9e/eu1LHiHXnkkZx77rkAHH/88fz9738H4B//+AePPPIIADk5ObRs2ZKtW7eWuZ+5c+fy5S9/GYC8vDy6du3KkiVLABgzZgwtW7YEoH///qxcuZIuXbpUOWYRqRk7dsDixbBoESxcGH4uWgRLl8KBA7Fy7dpBXh5MmBB+Fj2OPTa98SmZZjF3Z8CAAbzxxhuHrXvhhRd49dVXee655/jud7/L/Pnzq3ycop6mDzzwAP/+97954YUXKCgo4N133+XSSy9l2LBhvPDCC5xxxhk8+OCDjB49usx9NWjQgEOHDhW/jr8dJDc3t/hYOTk5FBYWVileL2fC+4YNGxY/T+UYIlL9Dh2CNWtiibLosXgxrF0bK5eTA716hSR5/vmxhNm3L7RunZnYlUyrqhI1yHRp2LAhGzdu5I033mD48OEcOHCAJUuW0K9fP1avXs3nPvc5Tj75ZB577DF27dpF8+bN2bFjR4X7/cxnPsPs2bOZPHkyjz76KCeffDIAy5YtY9iwYQwbNoznn3+e1atXs337dnr06MENN9zA8uXLef/998tNpt26deO+++7j0KFDfPzxx/znP/+pMJ4xY8Zw//33c9NNN3Hw4EF2795N8+bN2blzZ8LyI0eO5NFHH2X06NEsWbKEVatW0bdvX955550KjyUi6bd3L3z4YeKkuWdPrFzLliFJnnZayVpmjx6QRJ/LGqVkmsWOOOIInnzySW644Qa2b99OYWEhN910E3369OGyyy5j+/btuDtf+cpXaNWqFeeddx7jx4/n2Wef5ec//zmf/exnE+73nnvuYdq0adx5550cffTRzJw5E4Dp06fz4Ycf4u6MGTOGwYMH88Mf/pDf/e535Obm0r59e7797W+XG/OIESPo3r07AwcOJD8/n+OOO67C9/mzn/2Mq666ioceeoicnBzuv/9+hg8fzogRI8jPz+ess87iuuuuKy5/7bXXcvXVVzNw4EAaNGjArFmzStRIRST93GHTpsMT5qJF8NFHYX2Rrl1Dkhw5smTSbNcOsuUWbCvvklh9NnToUC89n+nChQvp169fhiKSuk6fL8lGhYUhOSZKmlu2xMo1ahQuw8Yny7w86NMHmjTJXPyVYWZvu/vQROtUMxURkQrFdwCKf3z4YeIOQBdddHgHoCPq8M2YSqYiIgKEDkAff5y4lllWB6Dzzot1/snLy1wHoExTMhURqWf27Su7A9Du3bFyLVtCv37Z0QEo05RMRUTqoMp0AOrWLXEHoGOOyZ4OQJmmZCoiksUKC2H58ljNsqwOQI0bh0uxJ54IX/hCLGH27p09HYBqMyVTEZEskOwIQO3bJx4BqEuXut0BKNN0arPIKaecwl//+tcSy+6++26uvfbacrcpusXn7LPPZtu2bYeVufXWW7nrrrvKPfYzzzzDggULil9/+9vf5qWXXqpM+AnNmTOneAjB6vbaa68xYMAACgoK2Lt3b7Xt9/vf/36J15/5zGeqbd9Svx06BKtWwd/+BvfcA9deC6NHQ8eOof2yqFZ5550hofbtC//1XzBrFvzv/8LWrbBuHbzyCtx/P9x4I5xxRriPU4k0vVQzzSITJ05k9uzZnHHGGcXLZs+ezZ133pnU9i+++GKVj/3MM89w7rnn0r9/fyDMBlPbPfroo3z1q19l6tSp1brf73//+3z9618vfp2Jae0kuyU7AlCrVqFWecYZIXH26xfrAJSbm7n45XD6XyWLjB8/nj/96U/s378fgBUrVrB27VpOPvlkrrnmGoYOHcqAAQO45ZZbEm7frVs3Nm3aBMDtt99O3759OfXUU1m8eHFxmV//+teccMIJDB48mM9//vPs2bOH119/neeee47p06dTUFDAsmXLmDJlSvH8oS+//DJDhgxh4MCBTJs2rTi+bt26ccstt3DccccxcOBAFi1aVO7727JlC2PHjmXQoEGcdNJJvP/++wD885//LJ4EfciQIezcuZN169YxcuRICgoKyM/PP2xKuQcffJDHH3+c2267jUmTJh1WA77++uuZNWtWuXHu2rWreCq3QYMG8dRTTzFjxgz27t1LQUEBkyZNAsLUcRDGBJ4+fTr5+fkMHDiQP/zhD0CofZ9yyimMHz+evLw8Jk2aVO74wVI3uMP69fDPf8Ivfwk33wxnnx0SYdOmMHgwXHwx3HprqFW2bw9XXQUPPABz5sAnn4Q2zzfegJkzYcYMuOCCkFSVSGuhsqaTqe+P2joF29lnn+3PPPOMu7v/4Ac/8K9+9avu7r5582Z3D1OUjRo1yt977z13Lzn9WdeuXX3jxo3+1ltveX5+vu/evdu3b9/uPXv2LJ6abdOmTcXH+sY3vuH33HOPu7tffvnl/sQTTxSvK3q9d+9e79y5sy9evNjd3SdPnlw8XVrXrl2Lt7/33nv9iiuuOOz9vPLKK37OOee4e5jO7dZbb3V395dfftkHDx7s7mFKuLlz57q7+86dO/3AgQN+1113+fe+973i97xjx47D9h0fc/xx3N2vu+46nzlzZrlxfu1rX/Mbb7yxeJstW7a4u3vTpk1LHKfo9ZNPPumnnnqqFxYW+ieffOJdunTxtWvX+iuvvOItWrTw1atX+8GDB/2kk07y11577bB4a8PnSyrv00/dFy1yf+YZ9x/+0H3KFPeTTnJv1arkFGBNmrgPGeI+caL7d77j/oc/uL/3nnuCWQullkJTsFW/TM3AVnSp94ILLmD27Nk8/PDDADz++OP86le/orCwkHXr1rFgwQIGDRqUcB+vvfYaF154IU2iLnznn39+8bp58+bxzW9+k23btrFr164Sl5QTWbx4Md27d6dPnz4AXH755dx7773cdNNNAMVTtR1//PHF07qVZe7cuTz11FMAjB49ms2bN7N9+3ZGjBjBzTffzKRJkxg3bhydO3fmhBNOYNq0aRw4cICxY8dSUFBQ/omrQKI4X3rpJWbPnl1cpnUFd6PPnTuXiRMnkpOTQ7t27Rg1ahRvvvkmLVq04MQTT6Rz584AFBQUsGLFiuIJBCQ7bNuWeASgpUtDj9oiHTqES7ETJ5bsANS5s9ot6zIl0ywzduxYbr75Zt555x327t3Lcccdx0cffcRdd93Fm2++SevWrZkyZUqJqc0SsTJuHpsyZQrPPPMMgwcPZtasWcyZM6fc/XgFlyuLBphPZrqzRPsyM2bMmME555zDiy++yEknncRLL73EyJEjefXVV3nhhReYPHky06dP5wtf+EKZ+y5v6rey4nT3Ms9TsvGX3n/pY0jtUtQBqHQ75qJF4bJrkQYNwi0l/frBhReWnAIsmi5X6hkl0yrK1AxszZo145RTTmHatGlMnDgRgB07dtC0aVNatmzJ+vXr+fOf/8wpp5xS5j5GjhzJlClTmDFjBoWFhTz//PN86UtfAmDnzp106NCBAwcO8Oijj9KpUyeAMqc8y8vLY8WKFSxdupRevXrx29/+llGjRlXpvRVNnfatb32LOXPm0LZtW1q0aMGyZcsYOHAgAwcO5I033mDRokU0btyYTp06ceWVV7J7927eeeedcpNp15oP2UwAAB9JSURBVK5dWbBgAfv372ffvn28/PLLFdYMTz/9dH7xi19wd/TL3rp1K61btyY3N5cDBw6QW6rhauTIkfzyl7/k8ssvZ8uWLbz66qvceeedFbYVS83bsweWLDm8lrlkSegcVKRVq5AwzzqrZC2ze3e1W0pJSqZZaOLEiYwbN674EuTgwYMZMmQIAwYMoEePHowYMaLc7Y877jguvvhiCgoK6Nq1a4mp2L773e8ybNgwunbtysCBA4sT6CWXXMKVV17JPffcU9zxCKBRo0bMnDmTiy66iMLCQk444QSuvvrqKr2vW2+9lalTpzJo0CCaNGnCb37zGyDc/vPKK6+Qk5ND//79Oeuss4p7Mefm5tKsWTMeeeSRcvfdpUsXJkyYwKBBg+jduzdDhgypMJ5vfvObXHfddeTn55OTk8Mtt9zCuHHjuOqqqxg0aBDHHXccjz76aHH5Cy+8kDfeeIPBgwdjZtxxxx20b99eyTRDijoAJRoBaOXKWDmz2AhAn/tcrMdsXh4cfbRGAJLkaAq2MmgKNqlp+nxVzYEDsGxZ4qS5fXusXJMmh0//lZcXBmxv3Dhz8Uv20BRsIpL1tm49vB1z0aKQSOOboDt2DEly0qSSSbNTJ3UAkvRRMhWRWuPQoXAJNlEtc8OGWLnc3DCpdH4+jB8fm/6rb19o0SJz8Uv9pWQqIjVu9+6yOwDFd7Q+6qjQhlk0Z2bRo1u30KNWpLbQx7GSKnu7hEgy6mLfBfdwO0miWuaqVbFyRxwResfm5R0+b2bbtpmLX6QylEwroVGjRmzevJk2bdoooUq1cXc2b95Mo0aNMh1KlXz6aRi4INGABjt2xMo1axYuw8bPmdm3b+gAlKVvXaSYkmkldO7cmTVr1rBx48ZMhyJ1TKNGjYpHSKqttmxJXMtcvhwOHoyV69w5JMr4OTPz8kLHIP0PKnWVkmkl5Obm0r1790yHIZI2Bw+W3QEo/n/II48MHYCKBmsvSph9+kDz5pmLXyRTlExF6qFdu2KXZeMvzy5ZAtGkP0AYtCAvD8aOLVnL7NoVcnIyF79IbaNkKlJHucPatYlrmWvWxModcQT07BmS5JlnlmzPbNMmc/GLZBMlU5Est39/6ACUKGnu2hUr17x5bMi8+Fpmz54QNw6/iFSBkqlIlti8uewOQHET4tClS7g3c9q0kkmzfXt1ABJJFyVTkVqksBBWrEg8BdimTbFyDRuGy7DHHQeXXlqyA1DTphkLX6TeUjIVyYCdOxPfl/nhh+G+zSLHHBOS5LhxJWuZxx6rDkAitYmSqUiauMPHHye+NPvxx7FyOTmxDkDnnFOyA9BRR2UufhFJnpKpSIr27UvcAWjx4pIdgFq0CG2Zp54aS5ZFHYCOPDJz8YtI6pRMRZK0aVPiWuZHH5XsANS1a0iSJ59c8tJsu3bqACRSVymZisQpLAzJMVHS3LIlVq5Ro1CzHDoULrssljB791YHIJH6SMlU6qUdO8ruAHTgQKxcu3YhSV50Ucm2zK5dNdG0iMQomUqd5R5G+klUy1y7NlYuJyfMXJKXV3LezL59oXXrzMUvItlDyVSy3r59oUaZqAPQ7t2xci1bhg5ApefM7NFDHYBEJDVKppIV3MvvAFQ0t7ZZrANQ/LyZeXnhnk11ABKRdFAylVol2Q5AjRuHy7Annlhy3szevaFJk8zFLyL1k5KpZER8B6CFC2MJc+nSkh2A2rcPSXLChJK1zC5d1AFIRGoPJVNJm0OHEncAWry4ZAegBg1iHYAuuKDkgAatWmUufhGRZCmZSsr27i27A9CePbFyRR2ATj/98A5AubmZi19EJFVKppIUd9i4MXFb5ooViTsAjRqlDkAiUj8omUoJhYVhfsxESXPr1li5og5Aw4bB5ZerA5CI1G9KpvXUjh2JE2ZZHYAuvlgdgEREyqJkWocdOhSbAiy+x+yiRbBuXaxcog5ARZ2A1AFIRKRiSqZ1QGVGAMrLi3UA6ts3dAjq2VMdgEREUqFkmiWSHQEIYh2APvtZTQEmIlITlExrmcpOAXbCCTB5cixh9umjDkAiIjVNyTRDUpkCLC8Pjj1WHYBERGoLJdM00hRgIiL1g5Jpmrz0EowdW7IDUIsWIUmeemosYfbrpynARESynZJpmvTsCVdcUfLSbPv26gAkIlIXKZmmSffu8LOfZToKERGpCerCIiIikiIlUxERkRQpmYqIiKSoXiVTM+thZg+Z2ZOZjkVEROqOtCZTM1thZh+Y2btm9lYK+3nYzDaY2bwE6840s8VmttTMZpS3H3df7u5XVDUOERGRRGqiN+/n3H1TohVmdgyw1913xi3r5e5LSxWdBfwCeKTU9jnAvcBpwBrgTTN7DsgBflBqH9PcfUMqb0RERCSRTN8aMwq4xszOdvd9ZnYlcCFwdnwhd3/VzLol2P5EYKm7Lwcws9nABe7+A+DctEYuIiISSXebqQN/M7O3zeyqw1a6PwH8BZhtZpOAacCESuy/E7A67vWaaFlCZtbGzB4AhpjZ/5RR5jwz+9X27dsrEYaIiNRn6a6ZjnD3tdHl3L+b2SJ3fzW+gLvfEdUo7wd6uvuuSuw/0XhCnmBZ0bE2A1eXt0N3fx54fujQoVdWIg4REanH0lozdfe10c8NwB8Jl2VLMLPPAvnR+lsqeYg1QJe4152BtWWUFRERSYu0JVMza2pmzYueA6cD80qVGQL8GrgAmAocZWbfq8Rh3gR6m1l3MzsSuAR4rjriFxERSVY6a6btgLlm9h7wH+AFd/9LqTJNgIvcfZm7HwIuB1aW3pGZ/R54A+hrZmvM7AoAdy8Ergf+CiwEHnf3+Wl7RyIiIgmYe5lNjPXa0KFD/a23qnxrrIiI1DFm9ra7D020rl6NgCQiIpIOSqYiIiIpUjIVERFJkZKpiIhIipRMRUREUqRkKiIikqKkhhM0s05A1/jypYcFFBERqa8qTKZm9iPgYmABcDBa7ICSqYiICMnVTMcCfd19f7qDERERyUbJtJkuB3LTHYiIiEi2SqZmugd418xeBoprp+5+Q9qiEhERySLJJNPn0EwsIiIiZaowmbr7b6LpzfpEixa7+4H0hiUiIpI9kunNewrwG2AFYEAXM7tct8aIiIgEyVzm/TFwursvBjCzPsDvgePTGZiIiEi2SKY3b25RIgVw9yWod6+IiEixZGqmb5nZQ8Bvo9eTgLfTF5KIiEh2SSaZXgNcB9xAaDN9FbgvnUGJiIhkk2R68+4HfhI9REREpJQyk6mZPe7uE8zsA8JYvCW4+6C0RiYiIpIlyquZ3hj9PLcmAhEREclWZfbmdfd10dNr3X1l/AO4tmbCExERqf2SuTXmtATLzqruQERERLJVeW2m1xBqoD3N7P24Vc2B19MdmIiISLYor830MeDPwA+AGXHLd7r7lrRGJSIikkXKazPd7u4rgJ8BW+LaSw+Y2bCaClBERKS2S6bN9H5gV9zr3dEyERERIblkau5efJ+pux8iuZGTRERE6oVkkulyM7vBzHKjx43A8nQHJiIiki2SSaZXA58BPgbWAMOAq9IZlIiISDZJZmzeDcAlNRCLiIhIVqowmZrZ0cCVQLf48u4+LX1hiYiIZI9kOhI9C7wGvAQcTG84IiIi2SeZZNrE3f877ZGIiIhkqWQ6IP3JzM5OeyQiIiJZKplkeiMhoe41sx1mttPMdqQ7MBERkWyRTG/e5jURiIiISLZKpjfvyETL3f3V6g9HREQk+yTTAWl63PNGwInA28DotEQkIiKSZZK5zHte/Gsz6wLckbaIREREskwyHZBKWwPkV3cgIiIi2SqZNtOfA0WzxhwBFADvpTMoERGRbJJMm+lbcc8Lgd+7+7/SFI+IiEjWKTOZmtnL7j4G6K8RkERERMpWXs20g5mNAs43s9mAxa9093fSGpmIiEiWKC+ZfhuYAXQGflJqnaNbY0RERIBykqm7Pwk8aWbfcvfv1mBMIiIiWaXCW2OUSEVERMpXlftMRUREJI6SqYiISIoqTKZm1tPMGkbPTzGzG8ysVfpDExERyQ7J1EyfAg6aWS/gIaA78FhaoxIREckiySTTQ+5eCFwI3O3uXwE6pDcsERGR7JFMMj1gZhOBy4E/Rcty0xeSiIhIdkkmmU4FhgO3u/tHZtYd+F16wxIREckeycxnugC4AcDMWgPN3f2H6Q5MREQkWyTTm3eOmbUws6MIU6/NNLPSwwuKiIjUW8lc5m3p7juAccBMdz8eODW9YYmIiGSPZJJpAzPrAEwg1gFJREREIskk09uAvwLL3P1NM+sBfJjesERERLJHMh2QngCeiHu9HPh8OoMSERHJJsl0QOpsZn80sw1mtt7MnjKzzjURnIiISDZI5jLvTOA5oCPQCXg+WiYiIiIkl0yPdveZ7l4YPWYBR6c5LhERkayRTDLdZGaXmVlO9LgM2JzuwERERLJFMsl0GuG2mE+AdcD4aJmIiIiQXG/eVcD5NRCLiIhIViozmZrZzwEva72735CWiERERLJMeTXTt2osChERkSxWZjJ199/UZCAiIiLZKpkOSCIiIlIOJVMREZEUlZlMzexH0c+Lai4cERGR7FNezfRsM8sF/qemghEREclG5fXm/QuwCWhqZjsAI9wqY4C7e4saiE9ERKTWK7Nm6u7T3b0l8IK7t3D35vE/azBGERGRWi2ZEZAuMLN2wAnRon+7+8b0hiUiIpI9kpnP9CLgP8BFhDF6/2Nm49MdmIiISLaosGYKfBM4wd03AJjZ0cBLwJPpDExERCRbJHOf6RFFiTSyOcntRERE6oVkaqZ/MbO/Ar+PXl8MvJi+kERERLJLMh2QppvZOOBkwm0xv3L3P6Y9MhERkSyRTM0Ud38aeDrNsYiIiGQltX2KiIikSMlUREQkRUqmIiIiKaqwzdTMPiCMyRtvO/AW8D1335yOwERERLJFMh2Q/gwcBB6LXl8S/dwBzALOq/6wREREskcyyXSEu4+Ie/2Bmf3L3UeY2WXpCkxERCRbJNNm2szMhhW9MLMTgWbRy8K0RCUiIpJFkqmZfhF42MyaEQZt2AFcYWZNgR+kMzgREZFskMwISG8CA82sJWDuvi1u9eNpi0xERCRLJDMFW0sz+wnwMvCSmf04SqwiIiJCcm2mDwM7CXOZTiBc5p2ZzqBERESySTJtpj3d/fNxr79jZu+mKyAREZFsk0zNdK+ZnVz0wsxGAHvTF5KIiEh2SaZmejXwSFw76Vbg8vSFJCIikl2S6c37HjDYzFpEr3eY2U3A++kOTkREJBskPdC9u+9w9x3Ry5vTFI+IiEjWqeqsMVatUYiIiGSxqibT0rPIiIiI1Ftltpma2U4SJ00DGqctIhERkSxTZjJ19+Y1GUhNMLMewDeAlu4+PtPxiIhI3VDVy7xJM7McM/s/M/tTCvt42Mw2mNm8BOvONLPFZrbUzGaUtx93X+7uV1Q1DhERkUTSnkyBG4GFiVaY2TFm1rzUsl4Jis4CzkywfQ5wL3AW0B+YaGb9zWygmf2p1OOYVN+IiIhIImlNpmbWGTgHeLCMIqOAZ82sUVT+SuCe0oXc/VVgS4LtTwSWRjXOT4HZwAXu/oG7n1vqsaE63pOIiEhp6a6Z3g18DTiUaKW7PwH8BZhtZpOAaYTB9JPVCVgd93pNtCwhM2tjZg8AQ8zsf8ooc56Z/Wr79u2VCENEROqztCVTMzsX2ODub5dXzt3vAPYB9wPnu/uuyhwm0S7LOdZmd7/a3Xu6e8KJzd39eXe/qmVLzTInIiLJSWfNdARwvpmtIFx+HW1mvytdyMw+C+QDfwRuqeQx1gBd4l53BtZWKVoREZEqSlsydff/cffO7t4NuAT4h7tfFl/GzIYAvwYuAKYCR5nZ9ypxmDeB3mbW3cyOjI7zXLW8ARERkSTVRG/e8jQBLnL3Ze5+iDAbzcrShczs98AbQF8zW2NmVwC4eyFwPfBXQo/hx919fo1FLyIiApi7RgZMZOjQof7WW29lOgwREaklzOxtdx+aaF2ma6YiIiJZT8lURETqru3b4fXXYUuioQqqT4WTg4uIiNR6+/fD4sXwwQfhMW9e+LlqVVj/+ONw0UVpO7ySqYiIZI9Dh2DFisOT5pIlUFgYyuTmQl4enHwyDBwI+fkwfHhaw1IyFRGR2mnDhsOT5vz5sHt3rEz37iFhXnhhSJoDB0KfPiGh1iAlUxERyaxdu0KSLJ04N26MlTn66JAov/jFWNIcMACaNctc3HGUTEVEpGYcOBAux5ZOmh99FCvTpElIluefH0uaAwfCMbV74i8lUxERqV7uoeNP6aS5aFFIqAA5OdC3L5x4IkybFkua3brBEdl3o4mSqYiIVN3mzYcnzXnzYOfOWJljjw2J8uyzY0mzb19o2DBzcVczJVMREanYnj2wYEHJpPnBB/DJJ7EyRx0VEuUXvhBLmgMGQD2YhUvJVEREYgoLYenSw2uby5aFy7cAjRqFJHnmmbF2zfx86NABLNHMmHWfkqmISH3kDmvWlLw0+8EHsHBhGAABQttl795QUACXXRarbfboEdo8pZiSqYhIXbd1a8lLs/Pmhce2bbEynTqFRHnaabHaZl4eNG6cubiziJKpiEhdsXdvqFmWTpwffxwr07JlSJQTJ5a8RNu6debirgOUTEVEss3Bg6ENs3TS/PDDMNwehJ6y/frB6NGxhDlwYKiB1tN2zXRSMhURqa3cYd26w3vQLlgA+/aFMmbQq1dIlhdfHEuavXpBA33F1xSdaRGR2mD79sM7A82bV3LqsA4dQrK89tpYbbN//zBqkGSUkqmISE3avz+MBFS6trl6daxM8+YhWY4fH0ua+fnQtm3m4pZyKZmKiKTDoUNhzNlEU4UdPBjK5OaGds2RI0t2Bjr2WLVrZhklUxGRVLiXPVXYnj2xcj16hGQ5blzsfs3evWt8qjBJDyVTEZFk7dyZeKqwTZtiZY45JiTKK6+MJc3+/WvNVGGSHkqmIiKlffpp4qnCVqyIlWnaNFySHTu25CXaWj5VmKSHkqmI1F+HDsHKlYf3ol28ODZVWIMGYYaTk04Ktc2ixNm1a1ZOFSbpoWQqIvXDxo2H33Yybx7s2hUr07VrSJTnnRdLmn37wpFHZi5uyQpKpiJSt+zeHWvXjE+c69fHyrRpExLl1Kmxy7MDBkCLFpmLW7KakqmIZKcDB8LweaXbNT/6KDZVWJMmIUnGT0qdnw/t2unWE6lWSqYiUru5w6pVh7drLloUOgpBmA6sTx8YOhSmTIklzR491K4pNULJVERqj82bE7dr7tgRK9OlS0iWZ51Vsl2zUaPMxS31npKpiNS8PXvCYO2lE+e6dbEyrVuHRDl5cskh9Vq2zFzcImVQMhWR9CkshKVLDx+HdtmyWLtmo0ahXfP000u2a3booHZNyRpKpiKSOndYs+bw+TUXLgwDu0Nou+zdGwoK4LLLYomzR4/Q5imSxZRMRaRytm5N3K65bVusTKdOIVGedlqsXTMvDxo3zlzcImmkZCoiie3dG2qWpRPnxx/HyrRsGRLlxIkl2zVbt85c3CIZoGQqUt8dPBjaMEvfr7l0aRhuD6BhwzBY++jRJds1O3VSu6YISqYi9Yc7rF17eLvmggWwb18oYwa9eoVkecklscTZs2cYo1ZEEtJfh0hdtG1brC0zPnFu3Ror07FjqF1ed12sXbNfvzBqkIhUipKpSDbbvz9xu+bq1bEyLVqEZDlhQsl2zTZtMhe3SB2jZCqSDQ4eDGPOlm7X/PDDsA7CzCb9+sHIkSXbNbt0UbumSJopmYrUJu7wySeHX56dPz/0roWQGHv0CMly/PhY0uzdG3JzMxu/SD2lZCqSKTt2JG7X3Lw5VqZdu5Asv/SlWG2zf39o2jRzcYvIYZRMRdJt/35YvPjwIfVWrYqVadYs1C7HjYt1BsrPh6OPzlzcIpI0JVOR6nLoEKxYcXi75pIlYYxaCLeX5OXBiBEla5vHHqupwkSymJKpSFWsX5+4XXP37liZbt1Cohw7Nlbb7NMndBQSkTpFyVSkPLt2hSRZura5cWOsTNu2IVFecUUsaQ4YAM2bZy5uEalRSqYiAAcOhHbN+Hs1P/gg3I5SpEmTkCTPOy/WpjlwIBxzjG49EannlEylfnGHlSsPv0S7aFFIqBCmA+vbF044AaZNiyXN7t3VrikiCSmZSt21adPhSXPePNi5M1bm2GNDsjz77FhtMy8vDOwuIpIkJVPJfnv2hMHaS7drfvJJrMxRR4Vk+YUvlBxSr2XLzMUtInWGkqlkj8LCMC1Y6aS5bFm4fAvQqFFo1zzjjJJD6nXooHZNEUkbJVOpfdzDBNSlk+bChWEABAhtl717Q0EBXHZZLHH26BHaPEVEapCSqWTW1q2H96CdNy9MIVakU6eQKE89NZY08/KgcePMxS0iEkfJVGrGvn2xqcLiE+fHH8fKtGx5+KTUAwaE9k4RkVpMyVSq18GDsHx54qnCDh0KZRo2DFOFjR4du+1k4MBQA1W7pohkISVTqZqiqcJKJ80FC0pOFdazZ0iURRNTDxwIvXqFMWpFROoIfaNJxYqmCivdrhk/VVj79iFRXn11LGn266epwkSkXlAylZhPPw0jAZU3VVjz5rGpwuJvPWnbNnNxi4hkmJJpfRQ/VVh80oyfKiw3N/SYPfnkkvNrdu2qdk0RkVKUTOu6DRsOT5qlpwrr3j02VVhRbbN3b00VJiKSJCXTumLXrsRD6m3YECsTP1VYUU1TU4WJiKRMyTTbHDgQbjMpXdtcvjxWpmiqsHPPLTlVWLt2mYtbRKQOUzKtrdxh9erDk+aiRaGjEIRh8/r0gaFDYcqU2CVaTRUmIlKjlExrg61bY8kyfqqw7dtjZbp0CTXMM88sOVVYo0aZi1tERAAl05q1d29sSL342ubatbEyrVqFZDlpUsmpwlq1ylzcIiJSLiXTdNm8Gf75z5I1zqVLSw6p179/GLw9fki9jh1164mISJZRMk2Xd96Bz38+JMZevULCLBrAPT9fQ+qJiNQh+jZPl+HD4c03Q+2zSZNMRyMiImmkZJouzZqFXrYiIlLn6f4JERGRFCmZioiIpEjJVEREJEVKpiIiIilSMhUREUmRkqmIiEiKlExFRERSpGQqIiKSIiVTERGRFCmZioiIpMjcPdMx1EpmthFYmek40qwtsCnTQWQpnbuq07mrOp27qquOc9fV3Y9OtELJtB4zs7fcXQMIV4HOXdXp3FWdzl3Vpfvc6TKviIhIipRMRUREUqRkWr/9KtMBZDGdu6rTuas6nbuqS+u5U5upiIhIilQzFRERSZGSaT1kZl3M7BUzW2hm883sxkzHlE3MLMfM/s/M/pTpWLKJmbUysyfNbFH02Rue6ZiyhZl9JfpbnWdmvzezRpmOqbYys4fNbIOZzYtbdpSZ/d3MPox+tq7u4yqZ1k+FwH+5ez/gJOA6M+uf4ZiyyY3AwkwHkYV+BvzF3fOAwegcJsXMOgE3AEPdPR/IAS7JbFS12izgzFLLZgAvu3tv4OXodbVSMq2H3H2du78TPd9J+FLrlNmosoOZdQbOAR7MdCzZxMxaACOBhwDc/VN335bZqLJKA6CxmTUAmgBrMxxPreXurwJbSi2+APhN9Pw3wNjqPq6SaT1nZt2AIcC/MxtJ1rgb+BpwKNOBZJkewEZgZnSJ/EEza5rpoLKBu38M3AWsAtYB2939b5mNKuu0c/d1ECoTwDHVfQAl03rMzJoBTwE3ufuOTMdT25nZucAGd38707FkoQbAccD97j4E2E0aLrXVRVH73gVAd6Aj0NTMLstsVFKakmk9ZWa5hET6qLs/nel4ssQI4HwzWwHMBkab2e8yG1LWWAOscfeiKyBPEpKrVOxU4CN33+juB4Cngc9kOKZss97MOgBEPzdU9wGUTOshMzNC29VCd/9JpuPJFu7+P+7e2d27ETqA/MPdVUNIgrt/Aqw2s77RojHAggyGlE1WASeZWZPob3cM6rxVWc8Bl0fPLweere4DNKjuHUpWGAFMBj4ws3ejZV939xczGJPUfV8GHjWzI4HlwNQMx5MV3P3fZvYk8A6hJ/7/oZGQymRmvwdOAdqa2RrgFuCHwONmdgXhn5OLqv24GgFJREQkNbrMKyIikiIlUxERkRQpmYqIiKRIyVRERCRFSqYiIiIpUjIVqSfM7KCZvRv3qLYRiMysW/wsHSL1je4zFak/9rp7QaaDEKmLVDMVqefMbIWZ/cjM/hM9ekXLu5rZy2b2fvTz2Gh5OzP7o5m9Fz2KhrbLMbNfR/Nu/s3MGmfsTYnUMCVTkfqjcanLvBfHrdvh7icCvyDMjEP0/BF3HwQ8CtwTLb8H+Ke7DyaMrzs/Wt4buNfdBwDbgM+n+f2I1BoaAUmknjCzXe7eLMHyFcBod18eTYDwibu3MbNNQAd3PxAtX+fubc1sI9DZ3ffH7aMb8Pdo8mXM7L+BXHf/XvrfmUjmqWYqIgBexvOyyiSyP+75QdQnQ+oRJVMRAbg47ucb0fPXCbPjAEwC5kbPXwauATCzHDNrUVNBitRW+s9RpP5oHDdLEMBf3L3o9piGZvZvwj/YE6NlNwAPm9l0YCOxWV5uBH4VzcBxkJBY16U9epFaTG2mIvVc1GY61N03ZToWkWyly7wiIiIpUs1UREQkRaqZioiIpEjJVEREJEVKpiIiIilSMhUREUmRkqmIiEiKlExFRERS9P9kRkayKpKf8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# ... training loop ...\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "EPOCHS = 100\n",
    "epochs = np.arange(1,EPOCHS+1)\n",
    "\n",
    "\n",
    "BETAS = (0.9, 0.999)\n",
    "WEIGHT_DECAY = 0\n",
    "\n",
    "\n",
    "# GRID SEARCH\n",
    "\n",
    "learningRates = np.linspace(0.0008,0.08,50)\n",
    "learnConfigurationNumbers = np.arange(1000,10000,500)\n",
    "eps=[1e-9,1e-8,1e-7,1e-6]\n",
    "# betas = ? I am not sure in what range to vary these\n",
    "\n",
    "NLR = len(learningRates)\n",
    "NLCN = len(learnConfigurationNumbers)\n",
    "NE = len(eps)\n",
    "\n",
    "LOSSES = torch.zeros(NLCN, NLR,NE,EPOCHS)\n",
    "LossValid = torch.zeros(NLCN, NLR,NE,EPOCHS)\n",
    "\n",
    "Nconf_valid = 500\n",
    "phivalid = torch.rand((Nconf_valid,Nt,Nx),**torchTensorArgs).real+1.j*tpOffset \n",
    "\n",
    "BigLoss = torch.zeros(NLCN, NLR,NE)\n",
    "\n",
    "numPRACLLayers = 1\n",
    "internalLayer = 2\n",
    "\n",
    "for i in range(NLCN):        # number of training configurations \n",
    "    \n",
    "    Nconf_learn = learnConfigurationNumbers[i]\n",
    "    phiR = torch.rand((Nconf_learn,Nt,Nx),**torchTensorArgs).real+1.j*tpOffset \n",
    "    \n",
    "    for j in range(NLR):   # learning rate \n",
    "        \n",
    "        LR = learningRates[j]\n",
    "        \n",
    "        for k in range(NE): # epsilon \n",
    "            \n",
    "            EPS = eps[k]\n",
    "            NN = []     # initialise the NN\n",
    "\n",
    "            for _ in range(numPRACLLayers):\n",
    "                NN.append(\n",
    "                    PRCL(\n",
    "                        Nt,\n",
    "                        Nx,\n",
    "                        coupling1 = generate_coupling(internalLayer),\n",
    "                        coupling2 = generate_coupling(internalLayer),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            NN = Sequential(NN)\n",
    "            \n",
    "            optimizer = optim.Adam(NN.parameters(), lr=LR, betas=BETAS, eps=EPS, weight_decay=WEIGHT_DECAY, amsgrad=False, maximize=True)\n",
    "\n",
    "            for epoch in tqdm(range(EPOCHS)):   \n",
    "\n",
    "                phiM, logDetJ_NN = NN(phiR)\n",
    "                loss = Loss(phiM, logDetJ_NN)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                LOSSES[i][j][k][epoch] = loss\n",
    "                \n",
    "                if epoch % 10 == 0 and epoch != 0:\n",
    "                    PATH = f\"NN, Nconf is {Nconf_learn}, learning rate is {LR}, epsilon is {EPS}, {epoch} epochs.pdf\"\n",
    "                    torch.save(NN.state_dict(), PATH)\n",
    "\n",
    "\n",
    "                # validation\n",
    "                with torch.no_grad():\n",
    "                    PHIvalid, logD = NN(phivalid)\n",
    "                    LossValid[i][j][k][epoch] = Loss(PHIvalid, logD)\n",
    "                    \n",
    "            BigLoss[i][j][k] = loss.item()\n",
    "            \n",
    "            #plotting\n",
    "\n",
    "            fig = plt.figure(figsize=(7,5))\n",
    "            plt.plot(epochs, LOSSES[i][j][k].detach().numpy(),  '-r', label='Test loss function')\n",
    "            plt.yscale('log')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Log of loss function')\n",
    "\n",
    "            plt.plot(epochs, LossValid[i][j][k].numpy(), '-b', label='Validation loss function')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.title('Learning rate: %.4f'%(LR))\n",
    "            plt.suptitle('Number of training configurations:  %.0f  \\n Epsilon:%.1e'%(Nconf_learn, EPS), y=1.05)\n",
    "            plt.savefig(f\"Loss fn plot, Nconf is {Nconf_learn}, learning rate is {LR}, epsilon is {EPS}.jpg\",bbox_inches='tight', dpi=150)\n",
    "            #plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
